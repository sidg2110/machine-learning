{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To iterate over JPG files in a directory\n",
    "import os\n",
    "\n",
    "# To read and manipulate images\n",
    "import cv2\n",
    "\n",
    "# CVXOPT library version\n",
    "# 'matrix' is the library representation of matrices\n",
    "# 'solvers' contains the actual methods for optimisation\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "# 'svm' is the class to represent SVM models in scikit-learn\n",
    "# 'confusion_matrix' calculates the confusion matrix for a given set of actual values and predicted values\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS TO CONSTRUCT TRAINING DATA FROM JPG FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates over all the files in a folder and forms the feature vector for each image\n",
    "def get_img_data(dir_path):\n",
    "    \n",
    "    # Each image is 16 x 16 x 3. Therefore, after flattening, each feature vector's dimension is 768\n",
    "    feature_len = 768\n",
    "    desired_width = 16\n",
    "    desired_height = 16\n",
    "\n",
    "    # Contains the feature vectors. Each column represents the feature vector of a particular example\n",
    "    data = np.empty((feature_len, 0))\n",
    "\n",
    "    # 'files' contains the names of the files in the directory\n",
    "    files = os.listdir(dir_path)\n",
    "\n",
    "    for file in files:\n",
    "        \n",
    "        # image_path is the relative path of the image (relative to this Jupyter Notebook)\n",
    "        image_path = os.path.join(dir_path, file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Resizing the image to 16 x 16 x 3\n",
    "        image = cv2.resize(image, (desired_width, desired_height))\n",
    "        \n",
    "        # Converts the OpenCV Image object to NumPy array\n",
    "        np_array = np.array(image)\n",
    "\n",
    "        # Flatten the 3D array to a 1D vector\n",
    "        np_vector = np_array.flatten().reshape((feature_len, 1))\n",
    "        \n",
    "        # Add this feature vector to the data array\n",
    "        data = np.concatenate((data, np_vector), axis=1)\n",
    "    \n",
    "    # Normalise the RGB values for each example\n",
    "    data = data/255\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Constructs the feature vector array and label array given the path to the folders containing images of each class\n",
    "def format_data(dir_path_1, dir_path_2):\n",
    "\n",
    "    class_1_data = get_img_data(dir_path_1)         # These examples are given class value +1\n",
    "    class_2_data = get_img_data(dir_path_2)         # These examples are given class value -1\n",
    "\n",
    "    pos_labels = np.full((1, class_1_data.shape[1]), 1.0)\n",
    "    neg_labels = np.full((1, class_2_data.shape[1]), -1.0)\n",
    "    \n",
    "    data_x = np.concatenate((class_1_data, class_2_data), axis=1)\n",
    "    data_y = np.concatenate((pos_labels, neg_labels), axis=1)\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "def format_data_multi(dir_path_list):\n",
    "    \n",
    "    label = 0.0\n",
    "    data_y = np.empty((1,0))\n",
    "    data_x = np.empty((768,0))\n",
    "    for path in dir_path_list:\n",
    "        imgs = get_img_data(path)\n",
    "        labels = np.full((1, imgs.shape[1]), label)\n",
    "\n",
    "        data_x = np.concatenate((data_x, imgs), axis=1)\n",
    "        data_y = np.concatenate((data_y, labels), axis=1)\n",
    "\n",
    "        label = label + 1.0\n",
    "\n",
    "\n",
    "    # This shuffles the training examples.\n",
    "    # This is necessary for k-fold cross validation question since we are using only a subset of training data there\n",
    "    combined = np.concatenate((data_x, data_y), axis=0)\n",
    "    np.random.shuffle(combined.T)       # np.random.shuffle() shuffles along the first dimension. Hence, transpose is taken first\n",
    "    \n",
    "    # Extracts the data_x and data_y from the combined array\n",
    "    data_x, data_y = combined[0:768], combined[768:769]\n",
    "    \n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS FOR SVM MODELS OPTIMISED USING CVXOPT PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_Cvxopt:\n",
    "\n",
    "    def __init__(self, training_data_x, training_data_y, kernel, C, gamma=0):\n",
    "        \n",
    "        '''\n",
    "        training_data_x, training_data_y : ndarrays | images and labels respectively\n",
    "        C : float | hyperparameter to determine importance of slack variables\n",
    "        kernel : string | 'linear' or 'gaussian'\n",
    "        gamma : float | used to compute gaussian kernel | needed only when kernel is gaussian\n",
    "        '''\n",
    "\n",
    "        self.training_data_x = training_data_x          # (768 x m)\n",
    "        self.training_data_y = training_data_y          # (1 x m)\n",
    "        self.kernel = kernel                            # 'linear' or 'gaussian'\n",
    "        self.C = C                                      # scalar\n",
    "        self.gamma = gamma                              # scalar\n",
    "        self.m = self.training_data_x.shape[1]          # scalar | number of training examples\n",
    "        self.p = np.zeros((self.m, self.m))             # (m x m)\n",
    "        self.q = np.zeros((self.m, 1))                  # (m, 1)\n",
    "        self.g = np.zeros((2*self.m, self.m))           # (2m x m)\n",
    "        self.a = np.zeros((1, self.m))                  # (1 x m)\n",
    "        self.b = np.zeros((1, 1))                       # scalar\n",
    "        self.h = np.zeros((2*self.m,))                  # (2m x 1)\n",
    "        self.alpha = np.zeros((self.m, 1))              # (1 x m)\n",
    "        self.n_sv=0                                     # scalar\n",
    "        self.sv_idx = []\n",
    "\n",
    "        self.get_matrices()                             # computes p, q, g, h, a, b\n",
    "        self.get_optimal_alpha()                        # optimises the dual to get alpha params\n",
    "\n",
    "    # computes p, q, g, h, a, b\n",
    "    def get_matrices(self):\n",
    "        \n",
    "        self.q = np.full((self.m,1), -1.0)\n",
    "\n",
    "        self.b = np.array([[0.0]])\n",
    "\n",
    "        matrix_g_pos = np.eye(self.m, dtype=float)\n",
    "        matrix_g_neg = (-1) * np.eye(self.m, dtype=float)\n",
    "        self.g = np.concatenate((matrix_g_pos, matrix_g_neg), axis=0)\n",
    "        \n",
    "        matrix_h_C = np.full((self.m, 1), self.C)\n",
    "        matrix_h_0 = np.full((self.m, 1), 0.0)\n",
    "        self.h = np.concatenate((matrix_h_C, matrix_h_0), axis=0)\n",
    "\n",
    "        self.a = self.training_data_y\n",
    "\n",
    "        # computation for p\n",
    "        kernel_matrix = self.get_kernel_matrix(self.training_data_x, self.training_data_x)\n",
    "        y_product = np.matmul(self.training_data_y.T, self.training_data_y)\n",
    "        self.p = kernel_matrix * y_product      \n",
    "            \n",
    "    # optmises the dual to get alpha parameters\n",
    "    def get_optimal_alpha(self):\n",
    "        \n",
    "        # in-built solver provided by CVXOPT\n",
    "        solution = solvers.qp(matrix(self.p), matrix(self.q), matrix(self.g), matrix(self.h), matrix(self.a), matrix(self.b))\n",
    "        \n",
    "        # optimal alpha parameters\n",
    "        self.alpha = np.array(solution['x'].T)\n",
    "        \n",
    "        # Approximates those alpha parameters to 0 or 1 which are very near to 0 or 1 respectively\n",
    "        # number of alpha parameters s.t 0 < alpha_param <= C are considered as support vectors\n",
    "        for i in range(self.m):\n",
    "            if (self.alpha[0, i] > 5 * 1e-9) and (self.alpha[0, i] < (1 - 1e-10)):\n",
    "                self.n_sv += 1\n",
    "                self.sv_idx.append(i)\n",
    "        \n",
    "    # computes the w vector | only for linear kernel\n",
    "    # w = (768 x 1)\n",
    "    def get_w(self):\n",
    "        if self.kernel == 'linear':\n",
    "            w = np.sum((self.alpha*self.training_data_y)*self.training_data_x, axis=1).reshape((768, 1))\n",
    "        return w\n",
    "\n",
    "    # computes the kernel matrix for given matrices x and y\n",
    "    # x = (768 x m) and y = (768 x n)\n",
    "    # kernel_matrix = (m x n)\n",
    "    def get_kernel_matrix(self, x, y):\n",
    "        x_T, y_T = x.T, y.T\n",
    "        \n",
    "        # computes the matrix if the kernel is gaussian\n",
    "        if self.kernel == 'gaussian':\n",
    "            norm_squared_x = np.sum(x_T ** 2, axis=1, keepdims=True)\n",
    "            norm_squared_y = np.sum(y_T ** 2, axis=1)\n",
    "            pairwise_distances = -2 * np.dot(x_T, y_T.T) + norm_squared_x + norm_squared_y\n",
    "            kernel_matrix = np.exp(-self.gamma * pairwise_distances)\n",
    "        \n",
    "        # computes the matrix if the kernel is linear\n",
    "        elif self.kernel == 'linear':\n",
    "            kernel_matrix = np.matmul(x_T, y)\n",
    "        \n",
    "        return kernel_matrix\n",
    "    \n",
    "    # computes 'b'\n",
    "    # since none of the obtained alpha are exactly 0, for computation purpose, all examples are considered to be support vectors\n",
    "    def get_b(self):\n",
    "\n",
    "        kernel_matrix = self.get_kernel_matrix(self.training_data_x, self.training_data_x)      # computes the kernel matrix\n",
    "        kernel_vector = np.sum(kernel_matrix, axis=1, keepdims=True)                            # sums over rows\n",
    "        \n",
    "        temp = self.alpha * self.training_data_y\n",
    "\n",
    "        sigma_y = np.sum(self.training_data_y, axis=1, keepdims=True)[0, 0]                     # computes the sum of all labels\n",
    "\n",
    "        b = (sigma_y - np.matmul(temp, kernel_vector)[0, 0]) / (self.m)\n",
    "    \n",
    "        return b\n",
    "    \n",
    "    # returns a list of predictions for examples in data_x\n",
    "    def get_predictions(self, data_x, data_y):\n",
    "\n",
    "        temp_1 = self.alpha * self.training_data_y\n",
    "        temp_2 = self.get_kernel_matrix(self.training_data_x, data_x)\n",
    "        \n",
    "        b = self.get_b()\n",
    "\n",
    "        # for example x, prediction is the sign of {dot(w, x) + b}\n",
    "        predictions = np.sign(np.matmul(temp_1, temp_2) + b)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    # returns the percentage accuracy over data_x\n",
    "    # similar to get_predictions() function. Just returns the percentage of accurate predictions, instead of list of predictions\n",
    "    def get_accuracy(self, data_x, data_y):\n",
    "        \n",
    "        examples = data_x.shape[1]\n",
    "\n",
    "        temp_1 = self.alpha * self.training_data_y\n",
    "        temp_2 = self.get_kernel_matrix(self.training_data_x, data_x)\n",
    "        \n",
    "        b = self.get_b()\n",
    "\n",
    "        predictions = np.sign(np.matmul(temp_1, temp_2) + b)\n",
    "\n",
    "        accuracy = np.sum(predictions == data_y) / examples\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS FOR SVM MODELS OPTIMISED USING SCIKIT LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_Sklearn:\n",
    "\n",
    "    def __init__(self, training_data_x, training_data_y, kernel, C, gamma=0):\n",
    "        \n",
    "        '''\n",
    "        training_data_x, training_data_y : ndarrays | images and labels respectively\n",
    "        C : float | hyperparameter to determine importance of slack variables\n",
    "        kernel : string | 'linear' or 'rbf' (gaussian)\n",
    "        gamma : float | used to compute gaussian kernel | needed only when kernel is gaussian\n",
    "        '''\n",
    "\n",
    "        self.training_data_x = training_data_x      # (768 x m)\n",
    "        self.training_data_y = training_data_y      # (1 x m)\n",
    "        self.kernel = kernel                        # 'linear' or 'rbf'\n",
    "        self.C = C                                  # scalar\n",
    "        self.gamma = gamma                          # scalar\n",
    "        self.m = self.training_data_x.shape[1]      # scalar | number of training examples\n",
    "        \n",
    "        self.model_svm()                            # optimises th dual of the svm\n",
    "    \n",
    "    # models the SVM problem and optmises the dual problem\n",
    "    # all the computed quantities are properties of 'svm_svc' object\n",
    "    def model_svm(self):\n",
    "        \n",
    "        self.svm_svc = svm.SVC(C=self.C, kernel=self.kernel, gamma=self.gamma)                  # constructs the model\n",
    "        self.svm_svc.fit(self.training_data_x.T, self.training_data_y.reshape(self.m,))         # optimises the dual\n",
    "\n",
    "    # returns the list of support vectors\n",
    "    def get_support_vectors(self):\n",
    "        return self.svm_svc.support_vectors_\n",
    "    \n",
    "    # returns a list of predictions for examples in data_x\n",
    "    def get_predictions(self, data_x):\n",
    "        temp = data_x.T\n",
    "        predictions = self.svm_svc.predict(temp)\n",
    "        predictions = np.array(predictions, ndmin=2)\n",
    "        return predictions\n",
    "    \n",
    "    # returns the percentage accuracy over data_x\n",
    "    # similar to get_predictions() function. Just returns the percentage of accurate predictions, instead of list of predictions\n",
    "    def get_accuracy(self, data_x, data_y):\n",
    "        examples = data_x.shape[1]\n",
    "        temp = data_x.T\n",
    "        predictions = self.svm_svc.predict(temp)\n",
    "        predictions = np.array(predictions, ndmin=2)\n",
    "        accuracy = np.sum(predictions == data_y)/examples\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING AND VALIDATION DATA FOR BINARY CLASSIFICATION <br>\n",
    "Entry No. = 2021EE10627 <br>\n",
    "Therefore, given classes are 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data for binary classification\n",
    "training_data_x, training_data_y = format_data('train/1/', 'train/2/')\n",
    "\n",
    "# validation data for binary classification\n",
    "validation_data_x, validation_data_y = format_data('val/1/', 'val/2/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY CLASSIFICATION USING CVXOPT <br>\n",
    "LINEAR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0489e+03 -1.2518e+04  8e+04  3e+00  3e-11\n",
      " 1: -6.8322e+02 -8.0216e+03  2e+04  5e-01  3e-11\n",
      " 2: -4.8967e+02 -3.1466e+03  4e+03  1e-01  2e-11\n",
      " 3: -4.0304e+02 -1.5654e+03  2e+03  5e-02  2e-11\n",
      " 4: -3.7361e+02 -7.7703e+02  6e+02  1e-02  1e-11\n",
      " 5: -3.8001e+02 -5.4972e+02  2e+02  4e-03  1e-11\n",
      " 6: -3.9526e+02 -4.6864e+02  8e+01  1e-03  2e-11\n",
      " 7: -4.0571e+02 -4.3399e+02  3e+01  2e-04  2e-11\n",
      " 8: -4.1139e+02 -4.2094e+02  1e+01  1e-05  2e-11\n",
      " 9: -4.1426e+02 -4.1682e+02  3e+00  3e-06  2e-11\n",
      "10: -4.1514e+02 -4.1559e+02  5e-01  4e-14  2e-11\n",
      "11: -4.1533e+02 -4.1537e+02  3e-02  4e-13  2e-11\n",
      "12: -4.1535e+02 -4.1535e+02  7e-04  2e-13  2e-11\n",
      "13: -4.1535e+02 -4.1535e+02  1e-05  7e-14  2e-11\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(770,\n",
       " array([[-0.33829427],\n",
       "        [ 0.26910357],\n",
       "        [-0.45842931],\n",
       "        [-1.22820474],\n",
       "        [ 0.41419763],\n",
       "        [ 0.62811933],\n",
       "        [-0.27813912],\n",
       "        [ 0.12548046],\n",
       "        [-0.12764508],\n",
       "        [-0.30381013],\n",
       "        [ 0.32458683],\n",
       "        [ 0.12995968],\n",
       "        [-0.40146586],\n",
       "        [ 0.4532173 ],\n",
       "        [-0.08664675],\n",
       "        [-0.03842715],\n",
       "        [ 0.45694184],\n",
       "        [-0.39768005],\n",
       "        [ 0.37417256],\n",
       "        [ 0.58534596],\n",
       "        [-0.74742502],\n",
       "        [-0.08005965],\n",
       "        [ 0.59831776],\n",
       "        [-0.40508779],\n",
       "        [-0.17143469],\n",
       "        [ 0.27094522],\n",
       "        [-0.27104476],\n",
       "        [-0.29056127],\n",
       "        [ 0.47396932],\n",
       "        [-0.1361778 ],\n",
       "        [ 0.15716831],\n",
       "        [ 0.5803348 ],\n",
       "        [-0.49376847],\n",
       "        [ 0.22674858],\n",
       "        [ 0.38627135],\n",
       "        [-0.36119134],\n",
       "        [-0.96171506],\n",
       "        [ 0.14108973],\n",
       "        [ 0.17247671],\n",
       "        [-1.22362419],\n",
       "        [ 0.40372029],\n",
       "        [ 0.2539434 ],\n",
       "        [-1.04778718],\n",
       "        [ 0.61972448],\n",
       "        [ 0.2042973 ],\n",
       "        [-0.13061881],\n",
       "        [ 0.32518099],\n",
       "        [-0.34748815],\n",
       "        [-0.92677099],\n",
       "        [ 0.09994612],\n",
       "        [ 0.56314956],\n",
       "        [-1.51370658],\n",
       "        [ 0.00866732],\n",
       "        [ 0.55075977],\n",
       "        [-0.21051068],\n",
       "        [ 0.39907967],\n",
       "        [-0.04385749],\n",
       "        [ 0.06427525],\n",
       "        [ 0.1840499 ],\n",
       "        [ 0.16802572],\n",
       "        [-0.48596174],\n",
       "        [-0.35493917],\n",
       "        [ 0.19524379],\n",
       "        [-0.0369157 ],\n",
       "        [-0.1373817 ],\n",
       "        [ 0.64589783],\n",
       "        [-0.35753358],\n",
       "        [-0.05108234],\n",
       "        [ 0.20108597],\n",
       "        [-0.00887358],\n",
       "        [ 0.20611545],\n",
       "        [-0.55326482],\n",
       "        [-0.09185813],\n",
       "        [ 0.67137791],\n",
       "        [ 0.44765902],\n",
       "        [-0.43873448],\n",
       "        [ 0.20395371],\n",
       "        [ 0.03339511],\n",
       "        [-0.10593656],\n",
       "        [ 0.41519776],\n",
       "        [-0.3024282 ],\n",
       "        [-0.23002987],\n",
       "        [ 0.06471638],\n",
       "        [ 0.11501409],\n",
       "        [ 0.06153127],\n",
       "        [ 0.05076888],\n",
       "        [-0.39169069],\n",
       "        [-0.48997721],\n",
       "        [ 0.42979044],\n",
       "        [-0.042188  ],\n",
       "        [ 0.12340034],\n",
       "        [-0.0193083 ],\n",
       "        [-0.26937043],\n",
       "        [ 0.6346524 ],\n",
       "        [ 0.09892936],\n",
       "        [-0.72338139],\n",
       "        [-0.49756583],\n",
       "        [ 0.06450221],\n",
       "        [-0.21198341],\n",
       "        [-0.29152257],\n",
       "        [ 0.26980095],\n",
       "        [ 0.4177474 ],\n",
       "        [-0.04933021],\n",
       "        [-0.0453378 ],\n",
       "        [-0.36005362],\n",
       "        [ 0.44817262],\n",
       "        [-0.25631103],\n",
       "        [-0.10336122],\n",
       "        [ 0.17086459],\n",
       "        [ 0.02684865],\n",
       "        [ 0.19781026],\n",
       "        [ 0.50297714],\n",
       "        [ 0.18961598],\n",
       "        [-0.39763704],\n",
       "        [-0.10034253],\n",
       "        [ 0.22080792],\n",
       "        [ 0.27393604],\n",
       "        [-0.00778977],\n",
       "        [ 0.51781577],\n",
       "        [ 0.04628646],\n",
       "        [-0.05744255],\n",
       "        [ 0.01614096],\n",
       "        [-0.15655737],\n",
       "        [-0.15878992],\n",
       "        [ 0.46022002],\n",
       "        [ 0.0391017 ],\n",
       "        [-0.15933801],\n",
       "        [-0.08082905],\n",
       "        [-0.32606133],\n",
       "        [-0.33196928],\n",
       "        [ 0.06426219],\n",
       "        [ 0.18294054],\n",
       "        [-0.04825617],\n",
       "        [ 0.19306633],\n",
       "        [-0.48394443],\n",
       "        [-0.05236264],\n",
       "        [ 0.68907685],\n",
       "        [-0.19681967],\n",
       "        [-0.76099724],\n",
       "        [ 0.28477473],\n",
       "        [ 0.21065774],\n",
       "        [-0.52250993],\n",
       "        [ 0.00580343],\n",
       "        [-0.08609444],\n",
       "        [-0.04058973],\n",
       "        [ 0.72214175],\n",
       "        [ 0.18799419],\n",
       "        [ 0.35249883],\n",
       "        [ 0.07103161],\n",
       "        [-0.03534705],\n",
       "        [ 0.27726708],\n",
       "        [-0.08687755],\n",
       "        [-0.27924947],\n",
       "        [ 0.20320623],\n",
       "        [-0.15038516],\n",
       "        [ 0.34343041],\n",
       "        [ 0.09263315],\n",
       "        [-0.43083631],\n",
       "        [-0.06677662],\n",
       "        [-0.55454143],\n",
       "        [-0.08444652],\n",
       "        [ 0.11683706],\n",
       "        [ 0.23587922],\n",
       "        [ 0.22931139],\n",
       "        [-0.25932958],\n",
       "        [ 0.32666254],\n",
       "        [-0.19675295],\n",
       "        [-0.21281167],\n",
       "        [ 0.01750386],\n",
       "        [-0.23492271],\n",
       "        [ 0.02274101],\n",
       "        [ 0.11417268],\n",
       "        [ 0.06629735],\n",
       "        [-0.01445115],\n",
       "        [-0.48791394],\n",
       "        [ 0.5640466 ],\n",
       "        [-0.06159093],\n",
       "        [ 0.18010424],\n",
       "        [ 0.47161817],\n",
       "        [-0.12287023],\n",
       "        [-0.07490102],\n",
       "        [ 0.30038851],\n",
       "        [ 0.02570491],\n",
       "        [ 0.05028802],\n",
       "        [ 0.29289859],\n",
       "        [-0.28420006],\n",
       "        [-0.13125869],\n",
       "        [ 0.23489885],\n",
       "        [-0.49450849],\n",
       "        [ 0.10239697],\n",
       "        [ 0.12013453],\n",
       "        [ 0.07080254],\n",
       "        [-0.10759752],\n",
       "        [ 0.18573523],\n",
       "        [ 0.31917494],\n",
       "        [ 0.1075771 ],\n",
       "        [-0.46598825],\n",
       "        [-0.17165573],\n",
       "        [ 0.5798238 ],\n",
       "        [-0.15736974],\n",
       "        [-0.08175474],\n",
       "        [-0.0657275 ],\n",
       "        [-0.0305825 ],\n",
       "        [-0.12253095],\n",
       "        [-0.2214504 ],\n",
       "        [ 0.37804845],\n",
       "        [-0.06824807],\n",
       "        [-0.54170533],\n",
       "        [ 0.07603398],\n",
       "        [ 0.85748882],\n",
       "        [-0.3036279 ],\n",
       "        [-0.30767942],\n",
       "        [ 0.12199023],\n",
       "        [ 0.03195486],\n",
       "        [-0.30129568],\n",
       "        [ 0.21551547],\n",
       "        [-0.26760321],\n",
       "        [-0.38940535],\n",
       "        [ 0.25890265],\n",
       "        [-0.57349769],\n",
       "        [ 0.10022121],\n",
       "        [ 0.51761954],\n",
       "        [-0.59901956],\n",
       "        [ 0.30775242],\n",
       "        [ 0.02370033],\n",
       "        [-0.19063113],\n",
       "        [ 0.10014269],\n",
       "        [-0.25439554],\n",
       "        [ 0.46523317],\n",
       "        [-0.09887736],\n",
       "        [ 0.10419152],\n",
       "        [ 0.54767796],\n",
       "        [-0.10803577],\n",
       "        [-0.25956607],\n",
       "        [ 0.03403858],\n",
       "        [-0.20698828],\n",
       "        [ 0.24052538],\n",
       "        [ 0.02337171],\n",
       "        [-0.45809106],\n",
       "        [ 0.19442956],\n",
       "        [-0.51127128],\n",
       "        [-0.12195065],\n",
       "        [ 0.22986809],\n",
       "        [-0.78317803],\n",
       "        [ 0.48642053],\n",
       "        [ 0.20694298],\n",
       "        [ 0.1953707 ],\n",
       "        [ 0.37644055],\n",
       "        [-0.81426803],\n",
       "        [-0.60923372],\n",
       "        [-0.01032924],\n",
       "        [-0.03911159],\n",
       "        [-0.739519  ],\n",
       "        [ 0.82354392],\n",
       "        [ 0.33987691],\n",
       "        [-0.19811009],\n",
       "        [-0.18206187],\n",
       "        [-0.12266509],\n",
       "        [ 0.03187359],\n",
       "        [ 0.41574089],\n",
       "        [-0.23254531],\n",
       "        [ 0.73446271],\n",
       "        [ 0.08799708],\n",
       "        [-0.81296427],\n",
       "        [ 0.36112799],\n",
       "        [ 0.17991152],\n",
       "        [-0.37451004],\n",
       "        [ 0.37351965],\n",
       "        [ 0.16112542],\n",
       "        [-0.80209819],\n",
       "        [-0.08533215],\n",
       "        [ 0.6534107 ],\n",
       "        [-0.20764617],\n",
       "        [ 0.18044428],\n",
       "        [-0.27061772],\n",
       "        [-0.32125236],\n",
       "        [-0.84840114],\n",
       "        [ 0.153654  ],\n",
       "        [ 0.42039134],\n",
       "        [ 0.02654182],\n",
       "        [ 0.17305608],\n",
       "        [-0.35768934],\n",
       "        [ 0.6204621 ],\n",
       "        [ 0.1644199 ],\n",
       "        [-0.08094576],\n",
       "        [ 0.00600776],\n",
       "        [-0.34933906],\n",
       "        [ 0.68263396],\n",
       "        [ 0.15176583],\n",
       "        [-0.02443813],\n",
       "        [-0.27153111],\n",
       "        [ 0.33996493],\n",
       "        [ 0.17256241],\n",
       "        [-0.43824688],\n",
       "        [ 0.38501844],\n",
       "        [-0.19606832],\n",
       "        [ 0.17267407],\n",
       "        [ 0.64647471],\n",
       "        [-0.37742882],\n",
       "        [-0.19786156],\n",
       "        [ 0.16680021],\n",
       "        [-0.06000097],\n",
       "        [-0.3164563 ],\n",
       "        [-0.05524067],\n",
       "        [-0.31513936],\n",
       "        [ 0.14433038],\n",
       "        [ 0.15599026],\n",
       "        [-0.26349888],\n",
       "        [ 0.19929773],\n",
       "        [-0.30085142],\n",
       "        [-0.4161457 ],\n",
       "        [ 0.28291846],\n",
       "        [-0.00690658],\n",
       "        [ 0.15154963],\n",
       "        [-0.07113416],\n",
       "        [-0.06269529],\n",
       "        [-0.02579777],\n",
       "        [-0.13054995],\n",
       "        [-0.60123905],\n",
       "        [ 0.68004534],\n",
       "        [-0.1496221 ],\n",
       "        [ 0.02909034],\n",
       "        [ 0.11833618],\n",
       "        [-0.00987264],\n",
       "        [-0.40761278],\n",
       "        [ 0.07986851],\n",
       "        [-0.05382516],\n",
       "        [ 0.11327044],\n",
       "        [ 0.49509268],\n",
       "        [-0.45571689],\n",
       "        [-0.50033845],\n",
       "        [ 0.05251499],\n",
       "        [ 0.26484469],\n",
       "        [-0.13680475],\n",
       "        [-0.03864563],\n",
       "        [ 0.34213923],\n",
       "        [ 0.18385245],\n",
       "        [-0.00268615],\n",
       "        [ 0.07861083],\n",
       "        [-0.12113534],\n",
       "        [-0.12965594],\n",
       "        [ 0.4184089 ],\n",
       "        [-0.14596892],\n",
       "        [-0.24359912],\n",
       "        [ 0.61028508],\n",
       "        [-0.55851984],\n",
       "        [-0.18170933],\n",
       "        [ 0.73277012],\n",
       "        [-1.16931981],\n",
       "        [ 0.32386881],\n",
       "        [ 0.65721849],\n",
       "        [ 0.49940931],\n",
       "        [-0.13896476],\n",
       "        [ 0.11698624],\n",
       "        [ 0.11033165],\n",
       "        [-0.46296492],\n",
       "        [ 0.29631635],\n",
       "        [-0.31493187],\n",
       "        [-0.21711363],\n",
       "        [ 0.35376226],\n",
       "        [ 0.11883606],\n",
       "        [ 0.2428538 ],\n",
       "        [-0.17993318],\n",
       "        [-0.42154832],\n",
       "        [-0.43815836],\n",
       "        [ 0.335024  ],\n",
       "        [-1.13104876],\n",
       "        [ 0.54161399],\n",
       "        [ 0.59881736],\n",
       "        [-0.16335048],\n",
       "        [-0.29727451],\n",
       "        [ 0.44285326],\n",
       "        [ 0.35011885],\n",
       "        [-0.16070363],\n",
       "        [ 0.09426338],\n",
       "        [ 0.05915165],\n",
       "        [ 0.1491812 ],\n",
       "        [-0.3361962 ],\n",
       "        [-0.68876391],\n",
       "        [ 0.43684465],\n",
       "        [ 0.47483094],\n",
       "        [-0.02598533],\n",
       "        [ 0.15898583],\n",
       "        [-0.71318378],\n",
       "        [-0.57392775],\n",
       "        [ 0.19846282],\n",
       "        [-0.35790276],\n",
       "        [-0.45380371],\n",
       "        [ 0.42454999],\n",
       "        [ 0.40782439],\n",
       "        [ 0.78603077],\n",
       "        [-0.23550073],\n",
       "        [-0.00245099],\n",
       "        [-0.09625401],\n",
       "        [-0.26409408],\n",
       "        [-0.08829806],\n",
       "        [ 0.08137195],\n",
       "        [-0.19233293],\n",
       "        [-0.01900971],\n",
       "        [ 0.40878463],\n",
       "        [-0.54817847],\n",
       "        [-0.64279029],\n",
       "        [-0.45447266],\n",
       "        [-0.38716553],\n",
       "        [-0.09916888],\n",
       "        [ 0.04577114],\n",
       "        [ 0.02566136],\n",
       "        [ 0.16908985],\n",
       "        [ 0.08939745],\n",
       "        [-0.43242082],\n",
       "        [ 0.06588874],\n",
       "        [ 0.13735331],\n",
       "        [-0.11568828],\n",
       "        [ 0.02614286],\n",
       "        [-0.71519166],\n",
       "        [-0.07544974],\n",
       "        [ 0.49021178],\n",
       "        [ 0.63908571],\n",
       "        [-0.37237547],\n",
       "        [-0.16952722],\n",
       "        [ 1.09369205],\n",
       "        [-0.60803498],\n",
       "        [-0.70933398],\n",
       "        [ 0.71223124],\n",
       "        [-0.16837226],\n",
       "        [-0.37739957],\n",
       "        [-0.78089519],\n",
       "        [-0.12708911],\n",
       "        [ 0.41511065],\n",
       "        [-0.23820548],\n",
       "        [ 0.28527235],\n",
       "        [ 0.12542951],\n",
       "        [-0.46047017],\n",
       "        [ 1.05029794],\n",
       "        [-0.79142525],\n",
       "        [-0.02159694],\n",
       "        [ 0.34510874],\n",
       "        [-1.09729155],\n",
       "        [ 0.46978154],\n",
       "        [-0.00256243],\n",
       "        [-0.06730438],\n",
       "        [-0.66722178],\n",
       "        [ 0.18112965],\n",
       "        [ 0.74547465],\n",
       "        [-0.1038366 ],\n",
       "        [ 0.34868987],\n",
       "        [ 0.12829606],\n",
       "        [ 0.11905602],\n",
       "        [ 0.51720593],\n",
       "        [ 0.27087912],\n",
       "        [-0.39463593],\n",
       "        [-0.11765318],\n",
       "        [ 0.35476213],\n",
       "        [-0.0430181 ],\n",
       "        [-0.09761465],\n",
       "        [-0.1484331 ],\n",
       "        [-0.48353109],\n",
       "        [-0.03616457],\n",
       "        [ 0.04247788],\n",
       "        [-0.55075145],\n",
       "        [ 0.2827153 ],\n",
       "        [ 0.34215695],\n",
       "        [-0.88783445],\n",
       "        [ 0.18850265],\n",
       "        [ 0.29974371],\n",
       "        [-0.03265163],\n",
       "        [-0.42467793],\n",
       "        [ 0.11599664],\n",
       "        [ 0.04097644],\n",
       "        [-0.21526801],\n",
       "        [-0.15854594],\n",
       "        [ 0.25290066],\n",
       "        [ 0.01718138],\n",
       "        [-0.0549831 ],\n",
       "        [ 0.55889837],\n",
       "        [ 0.026597  ],\n",
       "        [-0.27318663],\n",
       "        [-0.64663062],\n",
       "        [ 0.2632205 ],\n",
       "        [-0.33951142],\n",
       "        [-0.62847383],\n",
       "        [ 0.41579561],\n",
       "        [-0.19941919],\n",
       "        [-0.19076415],\n",
       "        [ 0.20563564],\n",
       "        [-0.25159873],\n",
       "        [ 0.29348757],\n",
       "        [ 0.10698846],\n",
       "        [ 0.00391944],\n",
       "        [-0.49504201],\n",
       "        [-0.32161446],\n",
       "        [-0.38462187],\n",
       "        [-0.56660398],\n",
       "        [ 0.37375575],\n",
       "        [ 0.47994952],\n",
       "        [ 0.00707178],\n",
       "        [-0.52724618],\n",
       "        [ 0.17726305],\n",
       "        [-0.37870059],\n",
       "        [-0.32760643],\n",
       "        [ 0.51437911],\n",
       "        [-0.22016087],\n",
       "        [ 0.17482129],\n",
       "        [-0.33490023],\n",
       "        [-0.2145185 ],\n",
       "        [-0.042645  ],\n",
       "        [ 0.2942803 ],\n",
       "        [ 0.08518544],\n",
       "        [ 0.43369743],\n",
       "        [ 0.14449564],\n",
       "        [-0.36902314],\n",
       "        [-0.16821162],\n",
       "        [-0.50533283],\n",
       "        [ 0.43375977],\n",
       "        [-0.6822616 ],\n",
       "        [-0.12353123],\n",
       "        [ 0.29008728],\n",
       "        [-0.78765881],\n",
       "        [ 0.52813596],\n",
       "        [-0.68446257],\n",
       "        [ 0.59748707],\n",
       "        [ 0.7587174 ],\n",
       "        [ 0.0683316 ],\n",
       "        [ 0.15782126],\n",
       "        [ 0.12544245],\n",
       "        [ 0.34744672],\n",
       "        [ 0.38668023],\n",
       "        [ 0.09499281],\n",
       "        [-0.37237957],\n",
       "        [-0.13191214],\n",
       "        [ 1.06677732],\n",
       "        [-0.14658782],\n",
       "        [ 0.05477271],\n",
       "        [ 0.40121811],\n",
       "        [-0.13834231],\n",
       "        [ 0.54831471],\n",
       "        [-0.07471288],\n",
       "        [ 0.03324175],\n",
       "        [ 0.26303765],\n",
       "        [ 0.24874454],\n",
       "        [-0.04554967],\n",
       "        [-0.51218015],\n",
       "        [-0.23768886],\n",
       "        [-0.30880866],\n",
       "        [-0.95512782],\n",
       "        [ 0.72137399],\n",
       "        [-0.31882085],\n",
       "        [ 0.07074622],\n",
       "        [ 1.14102719],\n",
       "        [ 0.33446005],\n",
       "        [-0.19375792],\n",
       "        [-0.11420894],\n",
       "        [ 0.4869892 ],\n",
       "        [-0.24545686],\n",
       "        [-0.0454446 ],\n",
       "        [-0.13302659],\n",
       "        [-0.00165414],\n",
       "        [ 0.33922861],\n",
       "        [-0.78443469],\n",
       "        [ 0.4698137 ],\n",
       "        [ 0.28617995],\n",
       "        [-0.42589636],\n",
       "        [ 0.28678795],\n",
       "        [ 0.23978724],\n",
       "        [ 0.01527577],\n",
       "        [-0.46493851],\n",
       "        [-0.03601465],\n",
       "        [ 0.4404647 ],\n",
       "        [-0.48697662],\n",
       "        [ 0.007813  ],\n",
       "        [-0.39189584],\n",
       "        [ 0.10542279],\n",
       "        [-0.52520017],\n",
       "        [ 0.04662393],\n",
       "        [ 0.27671532],\n",
       "        [-0.41075117],\n",
       "        [-0.38624043],\n",
       "        [-0.10444627],\n",
       "        [ 0.42994878],\n",
       "        [ 0.06872695],\n",
       "        [ 0.29118768],\n",
       "        [-0.24349565],\n",
       "        [-0.33745478],\n",
       "        [-0.1480812 ],\n",
       "        [-0.04128738],\n",
       "        [-0.21027323],\n",
       "        [ 0.18577164],\n",
       "        [ 0.73038485],\n",
       "        [-0.42519642],\n",
       "        [ 0.10015086],\n",
       "        [ 0.34286207],\n",
       "        [-0.91952831],\n",
       "        [ 0.52340775],\n",
       "        [-0.09745397],\n",
       "        [-0.42950267],\n",
       "        [ 0.17352218],\n",
       "        [ 0.07101088],\n",
       "        [-0.16218835],\n",
       "        [ 0.14293495],\n",
       "        [ 0.09978439],\n",
       "        [-0.2518931 ],\n",
       "        [ 0.18238268],\n",
       "        [ 0.27031094],\n",
       "        [ 0.27555823],\n",
       "        [ 0.39749803],\n",
       "        [-0.40106951],\n",
       "        [-0.3537007 ],\n",
       "        [ 0.28644676],\n",
       "        [-0.13288354],\n",
       "        [-0.19998229],\n",
       "        [ 0.00932709],\n",
       "        [-0.02316155],\n",
       "        [-0.5305839 ],\n",
       "        [ 0.25813043],\n",
       "        [ 0.32803957],\n",
       "        [ 0.42240752],\n",
       "        [-0.33439706],\n",
       "        [-0.2825778 ],\n",
       "        [-0.26866504],\n",
       "        [ 0.25253045],\n",
       "        [ 0.13869724],\n",
       "        [-0.28729536],\n",
       "        [ 0.05980537],\n",
       "        [-0.38944809],\n",
       "        [-0.15826535],\n",
       "        [-0.13259181],\n",
       "        [-0.09211381],\n",
       "        [ 0.26918729],\n",
       "        [-0.05830267],\n",
       "        [-0.50173461],\n",
       "        [ 0.209922  ],\n",
       "        [ 0.42299503],\n",
       "        [-0.95846825],\n",
       "        [ 0.33699814],\n",
       "        [ 0.11171605],\n",
       "        [ 0.06076862],\n",
       "        [-0.75155569],\n",
       "        [ 0.50024085],\n",
       "        [ 0.44869663],\n",
       "        [-0.04050234],\n",
       "        [ 0.4194981 ],\n",
       "        [ 0.31479313],\n",
       "        [ 0.05614427],\n",
       "        [-0.09577735],\n",
       "        [-0.08267872],\n",
       "        [ 0.18585766],\n",
       "        [-0.3277451 ],\n",
       "        [ 0.30954956],\n",
       "        [-0.13262959],\n",
       "        [-0.73313934],\n",
       "        [-0.20503626],\n",
       "        [-0.59030143],\n",
       "        [ 0.36993881],\n",
       "        [ 0.47272477],\n",
       "        [-0.11466191],\n",
       "        [ 0.23893811],\n",
       "        [ 0.02766706],\n",
       "        [-0.26231427],\n",
       "        [ 0.4268359 ],\n",
       "        [ 0.11020059],\n",
       "        [-1.06825055],\n",
       "        [-0.14082267],\n",
       "        [ 0.4772907 ],\n",
       "        [-0.59686118],\n",
       "        [ 0.39066636],\n",
       "        [-0.29028364],\n",
       "        [-0.02032272],\n",
       "        [ 0.16403639],\n",
       "        [ 0.28117047],\n",
       "        [-0.39842879],\n",
       "        [ 0.22293009],\n",
       "        [ 0.42515494],\n",
       "        [ 0.01378641],\n",
       "        [-0.11039599],\n",
       "        [ 0.17074345],\n",
       "        [-0.62036376],\n",
       "        [-0.46023475],\n",
       "        [ 0.0242422 ],\n",
       "        [-0.34414337],\n",
       "        [ 0.10601971],\n",
       "        [ 0.34678934],\n",
       "        [ 0.58488233],\n",
       "        [ 0.15390111],\n",
       "        [ 0.08797443],\n",
       "        [-0.41843573],\n",
       "        [ 0.0993464 ],\n",
       "        [ 0.12498878],\n",
       "        [ 0.45466098],\n",
       "        [ 0.10450254],\n",
       "        [-0.18161644],\n",
       "        [ 0.40670261],\n",
       "        [-0.88007133],\n",
       "        [ 0.29816156],\n",
       "        [ 0.29203501],\n",
       "        [-0.79290884],\n",
       "        [-0.08078281],\n",
       "        [ 0.14047764],\n",
       "        [ 0.37806083],\n",
       "        [ 0.44558101],\n",
       "        [ 0.40800918],\n",
       "        [-0.36223704],\n",
       "        [-0.02104519],\n",
       "        [ 0.11811667],\n",
       "        [-0.31317031],\n",
       "        [-0.14005253],\n",
       "        [ 0.76611588],\n",
       "        [-0.10664649],\n",
       "        [-0.07758224],\n",
       "        [ 0.32349527],\n",
       "        [ 0.109419  ],\n",
       "        [-0.19684358],\n",
       "        [-0.08706812],\n",
       "        [ 0.10586089],\n",
       "        [-0.05146948],\n",
       "        [-0.29436447],\n",
       "        [-0.06458824],\n",
       "        [-0.14112087],\n",
       "        [ 0.01330911],\n",
       "        [-0.54694918],\n",
       "        [-0.11015863],\n",
       "        [-0.55361231],\n",
       "        [-0.0427805 ],\n",
       "        [-0.08962955],\n",
       "        [-0.45330621],\n",
       "        [ 0.05544931],\n",
       "        [ 0.05676193],\n",
       "        [-0.1901848 ],\n",
       "        [-0.1638384 ],\n",
       "        [ 0.21632349],\n",
       "        [-0.59132892],\n",
       "        [-0.18764228],\n",
       "        [ 0.23143728],\n",
       "        [-0.19988777],\n",
       "        [-0.00892116],\n",
       "        [ 0.32169901],\n",
       "        [ 0.38878825],\n",
       "        [-0.33521074],\n",
       "        [-0.20564766],\n",
       "        [ 1.11568779],\n",
       "        [-0.04929663],\n",
       "        [-0.19340352],\n",
       "        [ 0.59218742],\n",
       "        [-0.78157396],\n",
       "        [-0.17947446],\n",
       "        [ 0.46605531],\n",
       "        [ 0.09556173],\n",
       "        [ 0.09616742],\n",
       "        [ 0.3142933 ],\n",
       "        [-0.30686675],\n",
       "        [ 0.29165456],\n",
       "        [ 0.60000199],\n",
       "        [ 0.02755436],\n",
       "        [-0.84474757],\n",
       "        [ 0.22808892],\n",
       "        [-0.47322858],\n",
       "        [-0.75132378],\n",
       "        [-0.39965867],\n",
       "        [ 0.07598891],\n",
       "        [ 0.45351483],\n",
       "        [ 0.30981954],\n",
       "        [-0.23197263],\n",
       "        [ 0.40443132],\n",
       "        [ 0.25366325],\n",
       "        [-0.06411422],\n",
       "        [ 0.24473161],\n",
       "        [ 0.34654048],\n",
       "        [-0.14229208],\n",
       "        [-0.10056188]]),\n",
       " 3.820871376132803,\n",
       " 97.37394957983193,\n",
       " 92.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cvxopt_linear = SVM_Cvxopt(training_data_x, training_data_y, 'linear', 1.0)\n",
    "\n",
    "w = svm_cvxopt_linear.get_w()       # computes w vector\n",
    "b = svm_cvxopt_linear.get_b()       # computes optimal bias (scalar 'b')\n",
    "\n",
    "accuracy_linear_cvx_train = svm_cvxopt_linear.get_accuracy(training_data_x, training_data_y)            # accuracy over training data\n",
    "accuracy_linear_cvx_valid = svm_cvxopt_linear.get_accuracy(validation_data_x, validation_data_y)        # accuracy over validation data\n",
    "\n",
    "svm_cvxopt_linear.n_sv, w, b, accuracy_linear_cvx_train, accuracy_linear_cvx_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION TO SHOW THE IMAGE REPRESENTED BY  VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the image using OpenCV given a NumPy row matrix\n",
    "def save_image(name, x):\n",
    "\n",
    "    # since 16 x 16 is a very small image, I scale each pixel to occupy 'scaling_factor' times area for better visualisation\n",
    "    scaling_factor = 20\n",
    "    \n",
    "    # since we had originally normalised the image, we denormalise it here\n",
    "    x *= 255\n",
    "\n",
    "    # OpenCV takes RGB values to be unsigned 8 bit integers. I round off each value to nearest integer and then convert it into uint8 data type\n",
    "    x_uint8 = np.round(x).astype(np.uint8)\n",
    "    \n",
    "    # reshapes the vector into 16x16x3 matrix\n",
    "    img_mat = x_uint8.reshape((16, 16, 3))\n",
    "    \n",
    "    # converts the matrix into an OpenCV image\n",
    "    img = cv2.cvtColor(img_mat, cv2.COLOR_RGB2BGR)    \n",
    "    # enlarges the image to occupy more area while preserving the resolution\n",
    "    en_img = cv2.resize(img, None, fx = scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # image is finally drawn on a canvas\n",
    "    # I define that canvas here\n",
    "    canvas_size = (en_img.shape[0], en_img.shape[1])\n",
    "    canvas = np.zeros((canvas_size[0], canvas_size[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    # place the image on the canvas\n",
    "    x_offset, y_offset = 0, 0\n",
    "    canvas[y_offset:y_offset + en_img.shape[0], x_offset:x_offset + en_img.shape[1]] = en_img\n",
    "\n",
    "    # show tha image and indefinitely wait for a key press before closing the window\n",
    "    cv2.imwrite(f'{name}.png', canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP 6 IMAGES AND 'W'- LINEAR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing indices of 6 examples with largest alpha paraemeters\n",
    "top_alpha_indices_linear = np.argsort(svm_cvxopt_linear.alpha.flatten())[-6:]\n",
    "\n",
    "# shows the 6 images with largest alpha parameters\n",
    "counter = 1\n",
    "for idx in top_alpha_indices_linear:\n",
    "    img_vector = training_data_x.T[idx]\n",
    "    save_image(f'lin-{counter}', img_vector)\n",
    "    counter += 1\n",
    "\n",
    "# values in 'w' can exceed 1. Therefore, while denormalising the vector, the values can exceed 255 (out of range)\n",
    "# therefore, I linearly map the values of weight vector to be between 0 and 1\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "w_scaled = (w - w_min) / (w_min-w_max)\n",
    "save_image('w', w_scaled)                  # shows image formed by 'w' in RGB format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY CLASSIFICATION USING CVXOPT <br>\n",
    "GAUSSIAN KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1603e+03 -1.2254e+04  7e+04  3e+00  3e-13\n",
      " 1: -7.2227e+02 -7.8489e+03  1e+04  4e-01  2e-13\n",
      " 2: -5.5732e+02 -1.6296e+03  1e+03  1e-02  2e-13\n",
      " 3: -6.5547e+02 -1.3428e+03  7e+02  6e-03  2e-13\n",
      " 4: -7.3815e+02 -1.1276e+03  4e+02  3e-03  2e-13\n",
      " 5: -7.6549e+02 -1.0696e+03  3e+02  2e-03  2e-13\n",
      " 6: -7.9988e+02 -9.9531e+02  2e+02  1e-03  2e-13\n",
      " 7: -8.1501e+02 -9.6205e+02  1e+02  6e-04  2e-13\n",
      " 8: -8.3208e+02 -9.2974e+02  1e+02  3e-04  2e-13\n",
      " 9: -8.4637e+02 -9.0356e+02  6e+01  2e-04  2e-13\n",
      "10: -8.5203e+02 -8.9350e+02  4e+01  1e-04  2e-13\n",
      "11: -8.6112e+02 -8.7806e+02  2e+01  1e-05  2e-13\n",
      "12: -8.6720e+02 -8.7014e+02  3e+00  1e-06  2e-13\n",
      "13: -8.6834e+02 -8.6880e+02  5e-01  1e-07  2e-13\n",
      "14: -8.6855e+02 -8.6856e+02  1e-02  3e-09  2e-13\n",
      "15: -8.6855e+02 -8.6855e+02  2e-04  4e-11  2e-13\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4760, 95.10504201680672, 93.5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_cvxopt_gaussian = SVM_Cvxopt(training_data_x, training_data_y, 'gaussian', 1.0, 0.001)\n",
    "\n",
    "accuracy_gaussian_cvx_train = svm_cvxopt_gaussian.get_accuracy(training_data_x, training_data_y)        # accuracy over training data\n",
    "accuracy_gaussian_cvx_valid = svm_cvxopt_gaussian.get_accuracy(validation_data_x, validation_data_y)    # accuracy over validation data\n",
    "\n",
    "svm_cvxopt_gaussian.n_sv, accuracy_gaussian_cvx_train, accuracy_gaussian_cvx_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP 6 IMAGES - GAUSSIAN KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list containing indices of 6 examples with largest alpha paraemeters\n",
    "top_alpha_indices_gaussian = np.argsort(svm_cvxopt_gaussian.alpha.flatten())[-6:]\n",
    "\n",
    "# shows the 6 images with largest alpha parameters\n",
    "counter = 1\n",
    "for idx in top_alpha_indices_gaussian:\n",
    "    img_vector = training_data_x.T[idx]\n",
    "    save_image(f'gau-{counter}', img_vector)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY CLASSIFICATION USING SCIKIT LEARN <br>\n",
    "LINEAR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sklearn_linear = SVM_Sklearn(training_data_x, training_data_y, 'linear', 1)\n",
    "\n",
    "sv_linear_sklearn = svm_sklearn_linear.get_support_vectors()            # list of support vectors\n",
    "\n",
    "accuracy_linear_sklearn_train = svm_sklearn_linear.get_accuracy(training_data_x, training_data_y)           # accuracy over training set\n",
    "accuracy_linear_sklearn_valid = svm_sklearn_linear.get_accuracy(validation_data_x, validation_data_y)       # accuracy over validation set\n",
    "\n",
    "sv_linear_sklearn.shape[0], accuracy_linear_sklearn_train, accuracy_linear_sklearn_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GET w AND b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the 'w' vector and 'b' learnt by SVM using sklearn\n",
    "w_sklearn = svm_sklearn_linear.svm_svc.coef_\n",
    "b_sklearn = svm_sklearn_linear.svm_svc.intercept_\n",
    "\n",
    "w_sklearn, b_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BINARY CLASSIFICATION USING SCIKIT LEARN <br>\n",
    "GAUSSIAN (RBF) KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sklearn_gaussian = SVM_Sklearn(training_data_x, training_data_y, 'rbf', 1, 0.001)\n",
    "\n",
    "sv_gaussian_sklearn = svm_sklearn_gaussian.get_support_vectors()        # list of support vectors\n",
    "\n",
    "accuracy_gaussian_sklearn_train = svm_sklearn_gaussian.get_accuracy(training_data_x, training_data_y)           # accuracy over training data\n",
    "accuracy_gaussian_sklearn_valid = svm_sklearn_gaussian.get_accuracy(validation_data_x, validation_data_y)       # accuracy over validation data\n",
    "\n",
    "sv_gaussian_sklearn.shape[0], accuracy_gaussian_sklearn_train, accuracy_gaussian_sklearn_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMON SUPPORT VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_lin_cvx = np.sort(svm_cvxopt_linear.sv_idx)       # Sorted list of indices of support vectors of linear SVM learnt using CVXOPT\n",
    "sv_gau_cvx = np.sort(svm_cvxopt_gaussian.sv_idx)     # Sorted list of indices of support vectors of gaussian SVM learnt using CVXOPT\n",
    "\n",
    "sv_lin_skl = np.sort(svm_sklearn_linear.svm_svc.support_)       # Sorted list of indices of support vectors of linear SVM learnt using sklearn\n",
    "sv_gau_skl = np.sort(svm_sklearn_gaussian.svm_svc.support_)     # Sorted list of indices of support vectors of gaussian SVM learnt using sklearn\n",
    "\n",
    "cvx_lin_gau = len(np.intersect1d(sv_lin_cvx, sv_gau_cvx))       # number of SVs common to linear and gaussian SVM learnt using CVXOPT\n",
    "skl_lin_gau = len(np.intersect1d(sv_lin_skl, sv_gau_skl))       # number of SVs common to linear and gaussian SVM learnt using sklearn\n",
    "\n",
    "lin_cvx_skl = len(np.intersect1d(sv_lin_cvx, sv_lin_skl))       # number of SVs common to linear SVMs learnt using CVXOPT and sklearn\n",
    "gau_cvx_skl = len(np.intersect1d(sv_gau_cvx, sv_gau_skl))       # number of SVs common to gaussian SVMs learnt using CVXOPT and sklearn\n",
    "\n",
    "sv_lin_cvx.shape, sv_gau_cvx.shape, sv_lin_skl.shape, sv_gau_skl.shape, cvx_lin_gau, skl_lin_gau, lin_cvx_skl, gau_cvx_skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING AND VALIDATION DATA FOR MULTICLASS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data for multi-class classification\n",
    "training_paths = ['train/0/', 'train/1/', 'train/2/', 'train/3/', 'train/4/', 'train/5/']\n",
    "training_data_x_multi, training_data_y_multi = format_data_multi(training_paths)\n",
    "\n",
    "# validation data for multi-class classification\n",
    "validation_paths = ['val/0/', 'val/1/', 'val/2/', 'val/3/', 'val/4/', 'val/5/']\n",
    "validation_data_x_multi, validation_data_y_multi = format_data_multi(validation_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTI CLASSIFICATION USING CVXOPT <br>\n",
    "GAUSSIAN KERNEL <br>\n",
    "WE HAVE COMB(6, 2) = 15 CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING THE TRAINING DATA FOR EACH CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_x_dict = {}       # contains training data_x mapped to each of the 15 (i, j) class pairs\n",
    "training_data_y_dict = {}       # contains traiing data_y mapped to each of the 15 (i, j) class pairs\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(i+1, 6):\n",
    "        \n",
    "        # filters the data for examples of class i or j\n",
    "        data_x_training = training_data_x_multi.T[(training_data_y_multi[0] == i) | (training_data_y_multi[0] == j)].T\n",
    "        \n",
    "        data_y_training = training_data_y_multi[0][(training_data_y_multi[0] == i) | (training_data_y_multi[0] == j)]\n",
    "        data_y_training = data_y_training.reshape((1, data_y_training.shape[0]))\n",
    "        # treats class i as 1 and class j as -1\n",
    "        data_y_training = np.where(data_y_training == i, 1.0, -1.0)\n",
    "\n",
    "        training_data_x_dict[(i, j)] = data_x_training\n",
    "        training_data_y_dict[(i, j)] = data_y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING THE VALIDATION DATA FOR EACH CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_x_dict = {}     # contains validation data_x mapped to each of the 15 (i, j) class pairs\n",
    "validation_data_y_dict = {}     # contains validation data_y mapped to each of the 15 (i, j) class pairs\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(i+1, 6):\n",
    "        \n",
    "        # filters the data for examples of class i or j\n",
    "        data_x_validation = validation_data_x_multi.T[(validation_data_y_multi[0] == i) | (validation_data_y_multi[0] == j)].T\n",
    "        \n",
    "        data_y_validation = validation_data_y_multi[0][(validation_data_y_multi[0] == i) | (validation_data_y_multi[0] == j)]\n",
    "        data_y_validation = data_y_validation.reshape((1, data_y_validation.shape[0]))\n",
    "        # treats class i as 1 and class j as -1\n",
    "        data_y_validation = np.where(data_y_validation == i, 1.0, -1.0)\n",
    "\n",
    "        validation_data_x_dict[(i, j)] = data_x_validation\n",
    "        validation_data_y_dict[(i, j)] = data_y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEARNING THE CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains the SVM model objects corresponding to each of the 15 (i, j) class pairs\n",
    "models_dict = {}\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(i+1, 6):\n",
    "        \n",
    "        data_x, data_y = training_data_x_dict[(i, j)], training_data_y_dict[(i, j)]\n",
    "        \n",
    "        model = SVM_Cvxopt(data_x, data_y, 'gaussian', 1.0, 0.001)\n",
    "        \n",
    "        models_dict[(i, j)] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D list containing the predictions over the entire training set made by each classifier\n",
    "# (15 x m)\n",
    "training_predictions = []\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(i+1, 6):\n",
    "        model = models_dict[(i, j)]\n",
    "        training_prediction = model.get_predictions(training_data_x_multi, training_data_y_multi)\n",
    "\n",
    "        training_answers = []\n",
    "        \n",
    "        # Replaces back -1 and 1 with the actual class label \n",
    "        for k in training_prediction[0]:\n",
    "            if k==1:\n",
    "                training_answers.append(i)\n",
    "            else:\n",
    "                training_answers.append(j)\n",
    "\n",
    "        # appends the predictions made the the (i, j) classifier\n",
    "        training_predictions.append(training_answers)\n",
    "\n",
    "training_predictions = np.array(training_predictions)\n",
    "\n",
    "# contains the final predictions made after computing the class with predicted the most\n",
    "final_class_train = []\n",
    "\n",
    "for i in range(training_data_x_multi.shape[1]):\n",
    "    # iterate over each example\n",
    "    column_train = training_predictions[:, i]\n",
    "    classes_train, freq_train = np.unique(column_train, return_counts=True)\n",
    "    class_train = classes_train[np.argmax(freq_train)]\n",
    "    final_class_train.append(class_train)\n",
    "\n",
    "final_class_train = np.array(final_class_train, ndmin=2)\n",
    "\n",
    "# calculates the accuracy over training dataset\n",
    "accuracy_multi_cvx_train = np.sum(final_class_train == training_data_y_multi) / training_data_y_multi.shape[1]\n",
    "\n",
    "accuracy_multi_cvx_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY ON VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D list containing the predictions over the entire training set made by each classifier\n",
    "# (15 x n) where n is the number of examples in the validation set\n",
    "validation_predictions = []\n",
    "\n",
    "for i in range(0, 6):\n",
    "    for j in range(i+1, 6):\n",
    "\n",
    "        model = models_dict[(i, j)]\n",
    "        \n",
    "        validation_prediction = model.get_predictions(validation_data_x_multi, validation_data_y_multi)\n",
    "\n",
    "        validation_answers = []\n",
    "        \n",
    "        # Replaces back -1 and 1 with the actual class label \n",
    "        for k in validation_prediction[0]:\n",
    "            if k==1:\n",
    "                validation_answers.append(i)\n",
    "            else:\n",
    "                validation_answers.append(j)\n",
    "\n",
    "        # appends the predictions made the the (i, j) classifier\n",
    "        validation_predictions.append(validation_answers)\n",
    "\n",
    "validation_predictions = np.array(validation_predictions)\n",
    "\n",
    "# contains the final predictions made after computing the class with predicted the most\n",
    "final_class_valid = []\n",
    "\n",
    "for i in range(validation_data_x_multi.shape[1]):\n",
    "    # iterate over each example\n",
    "    column_valid = validation_predictions[:, i]\n",
    "    classes_valid, freq_valid = np.unique(column_valid, return_counts=True)\n",
    "    class_valid = classes_valid[np.argmax(freq_valid)]\n",
    "    final_class_valid.append(class_valid)\n",
    "\n",
    "\n",
    "final_class_valid = np.array(final_class_valid, ndmin=2)\n",
    "\n",
    "# calculates the accuracy over validation dataset\n",
    "accuracy_multi_cvx_valid = np.sum(final_class_valid == validation_data_y_multi) / validation_data_y_multi.shape[1]\n",
    "\n",
    "accuracy_multi_cvx_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFUSION MATRIX FOR VALIDATION DATA (CVXOPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the confusion matrix for the model learnt using CVXOPT\n",
    "\n",
    "actual_values_cvx = validation_data_y_multi.flatten()           # contains the true labels\n",
    "predicted_values_cvx = final_class_valid.flatten()              # contains the predicted labels\n",
    "\n",
    "# 'confusion_matrix' is an in-built function in sklearn.metrics module\n",
    "confusion_matrix_cvx = confusion_matrix(actual_values_cvx, predicted_values_cvx)\n",
    "confusion_matrix_cvx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTI CLASSIFICATION USING SCIKIT LEARN <br>\n",
    "GAUSSIAN KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5683473389355742, 0.5583333333333333)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_sklearn_multi = SVM_Sklearn(training_data_x_multi, training_data_y_multi, 'rbf', 1, 0.001)\n",
    "\n",
    "accuracy_train_multi = svm_sklearn_multi.get_accuracy(training_data_x_multi, training_data_y_multi)               # accuracy over training set\n",
    "accuracy_validation_multi = svm_sklearn_multi.get_accuracy(validation_data_x_multi, validation_data_y_multi)      # accuracy over validation set\n",
    "\n",
    "accuracy_train_multi, accuracy_validation_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFUSION MATRIX FOR VALIDATION SET (SKLEARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 75,  22,  18,  27,  24,  34],\n",
       "       [  4, 150,   1,   6,  12,  27],\n",
       "       [ 11,   4, 125,  26,  22,  12],\n",
       "       [ 24,   6,  25, 126,  14,   5],\n",
       "       [ 18,  17,  58,  33,  68,   6],\n",
       "       [ 25,  23,  10,   8,   8, 126]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes the confusion matrix for the model learnt using sklearn\n",
    "\n",
    "actual_values_sklearn = validation_data_y_multi.flatten()                                               # contains the true labels\n",
    "predicted_values_sklearn = svm_sklearn_multi.get_predictions(validation_data_x_multi).flatten()         # contains the predicted labels\n",
    "\n",
    "# 'confusion_matrix' is an in-built function in sklearn.metrics module\n",
    "confusion_matrix_sklearn = confusion_matrix(actual_values_sklearn, predicted_values_sklearn)\n",
    "\n",
    "confusion_matrix_sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 MIS-LABELED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows 12 images which have not been predicted correctly\n",
    "\n",
    "wrg_img = 0     # we need 12 images\n",
    "idx = 0\n",
    "wrg_images = []\n",
    "while((idx < actual_values_sklearn.shape[0]) and (wrg_img < 12)):\n",
    "    # if the prediction is wrong, append the image to wrg_images\n",
    "    if actual_values_sklearn[idx] != predicted_values_sklearn[idx]:\n",
    "        img_vector = validation_data_x_multi.T[idx]\n",
    "        wrg_images.append([img_vector, actual_values_sklearn[idx], predicted_values_sklearn[idx]])\n",
    "        wrg_img += 1\n",
    "    idx += 1\n",
    "\n",
    "for v in wrg_images:\n",
    "    save_image(f'ms-{v[1]}-{v[2]}', v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-FOLD CROSS VALIDATION ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the average of the accuracies for the 5 validation subsets formed from the training data for a particular value of C\n",
    "def train_using_cv(training_data_x, training_data_y, c):\n",
    "    \n",
    "    total_train_examples = training_data_x.shape[1]\n",
    "    batch_size = (int) (total_train_examples/5)             # size of each of the 5 subsets\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        valid_start = i * batch_size\n",
    "        valid_end = valid_start + batch_size\n",
    "\n",
    "        # for (i)th iteration: validation set is from index 'valid_start' to 'valid_end-1' (both included)\n",
    "        validation_x = training_data_x[0:768, valid_start:valid_end]        # validation data_x for this iteration\n",
    "        validation_y = training_data_y[0:768, valid_start:valid_end]        # validation data_y for this iteration\n",
    "\n",
    "        # concatenates the data before and after the validation subset to get the training data for this iteration\n",
    "        train_x = np.concatenate((training_data_x[0:768, 0:valid_start], training_data_x[0:768, valid_end:total_train_examples]), axis=1)\n",
    "        train_y = np.concatenate((training_data_y[0:768, 0:valid_start], training_data_y[0:768, valid_end:total_train_examples]), axis=1)\n",
    "\n",
    "        model = SVM_Sklearn(train_x, train_y, 'rbf', c, 0.001)\n",
    "        \n",
    "        # accuracy over the validation set for this iteration\n",
    "        curr_accuracy = model.get_accuracy(validation_x, validation_y)\n",
    "\n",
    "        accuracy += curr_accuracy\n",
    "    \n",
    "    # averages the accuracy over 5 iterations\n",
    "    accuracy /= 5\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1e-5\n",
    "accuracy_1 = train_using_cv(training_data_x_multi, training_data_y_multi, 1e-5)\n",
    "accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1e-3\n",
    "accuracy_2 = train_using_cv(training_data_x_multi, training_data_y_multi, 1e-3)\n",
    "accuracy_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1\n",
    "accuracy_3 = train_using_cv(training_data_x_multi, training_data_y_multi, 1)\n",
    "accuracy_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 5\n",
    "accuracy_4 = train_using_cv(training_data_x_multi, training_data_y_multi, 5)\n",
    "accuracy_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 10\n",
    "accuracy_5 = train_using_cv(training_data_x_multi, training_data_y_multi, 10)\n",
    "accuracy_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEARNING AND VALIDATING ON ENTIRE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1e-5\n",
    "model_1 = SVM_Sklearn(training_data_x_multi, training_data_y_multi, 'rbf', 1e-5, 0.001)\n",
    "accuracy_1_entire = model_1.get_accuracy(validation_data_x_multi, validation_data_y_multi)\n",
    "\n",
    "accuracy_1_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1e-3\n",
    "model_2 = SVM_Sklearn(training_data_x_multi, training_data_y_multi, 'rbf', 1e-3, 0.001)\n",
    "accuracy_2_entire = model_2.get_accuracy(validation_data_x_multi, validation_data_y_multi)\n",
    "\n",
    "accuracy_2_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1\n",
    "model_3 = SVM_Sklearn(training_data_x_multi, training_data_y_multi, 'rbf', 1, 0.001)\n",
    "accuracy_3_entire = model_3.get_accuracy(validation_data_x_multi, validation_data_y_multi)\n",
    "\n",
    "accuracy_3_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 5\n",
    "model_4 = SVM_Sklearn(training_data_x_multi, training_data_y_multi, 'rbf', 5, 0.001)\n",
    "accuracy_4_entire = model_4.get_accuracy(validation_data_x_multi, validation_data_y_multi)\n",
    "\n",
    "accuracy_4_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 10\n",
    "model_5 = SVM_Sklearn(training_data_x_multi, training_data_y_multi, 'rbf', 10, 0.001)\n",
    "accuracy_5_entire = model_5.get_accuracy(validation_data_x_multi, validation_data_y_multi)\n",
    "\n",
    "accuracy_5_entire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTTING THE ACCURACIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the trend in 5-fold cross validation accuracy and accuracy on entire validation set with increasing value of C\n",
    "\n",
    "c = [1e-5, 1e-3, 1, 5, 10]      # values of C\n",
    "\n",
    "cv_accuracies = [accuracy_1, accuracy_2, accuracy_3, accuracy_4, accuracy_5]        # 5-fold cross validation accuracies\n",
    "entire_accuracies = [accuracy_1_entire, accuracy_2_entire, accuracy_3_entire, accuracy_4_entire, accuracy_5_entire]     # accuracies on the entire validation set\n",
    "\n",
    "plt.xscale('log')       # makes the x-axis log scaled\n",
    "\n",
    "plt.plot(c, cv_accuracies, label='cross-validation accuracies', color='blue')\n",
    "plt.plot(c, entire_accuracies, label='validation accuracies', color='red')\n",
    "\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
