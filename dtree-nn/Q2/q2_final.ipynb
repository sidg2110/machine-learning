{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING DATA <br>\n",
    "Can be of two types - custom, sk_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file_x, file_y, method='custom'):\n",
    "    x = np.load(file_x)\n",
    "    y = np.load(file_y)\n",
    "    x = 2*(0.5 - x/255)\n",
    "    y = y-1\n",
    "    y = y.astype('float')\n",
    "    x = x.astype('float')\n",
    "\n",
    "    constant = np.ones((x.shape[0], 1))\n",
    "    \n",
    "    if method == 'custom':\n",
    "        x = np.concatenate((x, constant), axis=1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTILITY CLASSES AND FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store the loss values in SGD\n",
    "# Used for stopping criterion\n",
    "class Queue:\n",
    "    def __init__(self, k):\n",
    "        self.q = []\n",
    "        self.size = int(k // 2)\n",
    "\n",
    "    def push(self, x):\n",
    "        self.q.append(x)\n",
    "    \n",
    "    def pop(self):\n",
    "        self.q = self.q[1:]\n",
    "    \n",
    "    def mean(self):\n",
    "        temp_1 = np.mean(self.q[0: self.size])\n",
    "        temp_2 = np.mean(self.q[self.size:])\n",
    "        return (abs(temp_1 - temp_2))\n",
    "\n",
    "def softmax(x):\n",
    "    denom = np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "    softmax = (np.exp(x)) / denom\n",
    "    return softmax\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp((-1) * x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.where(x>0, x, 0)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x>0, 1.0, 0.0)\n",
    "\n",
    "# Initialises a (m x n) matrix using Xavier Initialistion\n",
    "def xavier_init(m, n):\n",
    "    var = 2.0 / (m + n)\n",
    "    std_dev = np.sqrt(var)\n",
    "    return (np.random.normal(0, std_dev, (m,n)))\n",
    "\n",
    "# Initialises a (m x n) matrix with zeros\n",
    "def zero_init(m, n):\n",
    "    return np.zeros((m, n))\n",
    "\n",
    "\n",
    "def get_metrics(y_true, y_pred):\n",
    "    precision, recall, f1_score = [], [], []\n",
    "    class_names = [0, 1, 2, 3, 4]\n",
    "    metrics = classification_report(y_true, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
    "    for class_name in class_names:\n",
    "        precision.append(metrics[class_name]['precision'])\n",
    "        recall.append(metrics[class_name]['recall'])\n",
    "        f1_score.append(metrics[class_name]['f1-score'])\n",
    "    \n",
    "    return (precision, recall, f1_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA - FOR CUSTOM MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = import_data('x_train.npy', 'y_train.npy')\n",
    "test_x, test_y = import_data('x_test.npy', 'y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS FOR NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, train_x, train_y, batch_size, hidden_layers, n_classes, activation, learning_rate, lr_mode='constant'):\n",
    "        \n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.n_hidden_layers = len(hidden_layers)\n",
    "        self.n_layers = self.n_hidden_layers+1\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation = None\n",
    "        self.activation_derivative = None\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_derivative = sigmoid_derivative\n",
    "        elif activation == 'relu':\n",
    "            self.activation = relu\n",
    "            self.activation_derivative = relu_derivative\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_mode = lr_mode\n",
    "        self.m = train_x.shape[0]\n",
    "        self.n = train_x.shape[1]\n",
    "\n",
    "        self.weight_params = []\n",
    "        self.input_values = []\n",
    "        self.output_values = []\n",
    "        \n",
    "        self.init_params()\n",
    "        self.optimise_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        n_1 = self.hidden_layers[0]\n",
    "        w_1 = xavier_init(n_1+1, self.n)\n",
    "        w_1[:, -1:] = np.zeros((n_1+1, 1))\n",
    "        x_1 = zero_init(self.batch_size, self.n)\n",
    "        o_1 = zero_init(self.batch_size, n_1 + 1)\n",
    "\n",
    "        self.weight_params.append(w_1)\n",
    "        self.input_values.append(x_1)\n",
    "        self.output_values.append(o_1)\n",
    "\n",
    "        for layer in range(1, self.n_hidden_layers):\n",
    "            w_j = xavier_init(self.hidden_layers[layer]+1, self.hidden_layers[layer-1]+1)\n",
    "            w_j[:, -1:] = np.zeros((self.hidden_layers[layer]+1, 1))\n",
    "            x_j = zero_init(self.batch_size, self.hidden_layers[layer-1]+1)\n",
    "            o_j = zero_init(self.batch_size, self.hidden_layers[layer]+1)\n",
    "\n",
    "            self.weight_params.append(w_j)\n",
    "            self.input_values.append(x_j)\n",
    "            self.output_values.append(o_j)\n",
    "\n",
    "        w_last = xavier_init(self.n_classes, self.hidden_layers[-1]+1)\n",
    "        w_last[:, -1:] = np.zeros((self.n_classes, 1))\n",
    "        x_last = zero_init(self.batch_size, self.hidden_layers[-1]+1)\n",
    "        o_last = zero_init(self.batch_size, self.n_classes+1)\n",
    "        self.weight_params.append(w_last)\n",
    "        self.input_values.append(x_last)\n",
    "        self.output_values.append(o_last)\n",
    "\n",
    "    def forward_prop(self, X, Y):\n",
    "        batch_size = X.shape[0]\n",
    "        input_matrix = X\n",
    "        for layer in range(0, self.n_hidden_layers):\n",
    "            self.input_values[layer] = input_matrix\n",
    "            weight_matrix = self.weight_params[layer]\n",
    "            node_values = np.matmul(input_matrix, weight_matrix.T)\n",
    "            node_values = self.activation(node_values)\n",
    "            temp = node_values.T\n",
    "            temp[-1] = np.ones(batch_size)\n",
    "            self.output_values[layer] = temp.T\n",
    "            input_matrix = temp.T\n",
    "        \n",
    "        self.input_values[-1] = input_matrix\n",
    "        weight_matrix = self.weight_params[-1]\n",
    "        output_node_values = np.matmul(input_matrix, weight_matrix.T)\n",
    "        output_node_values = softmax(output_node_values)\n",
    "        self.output_values[-1] = output_node_values\n",
    "        \n",
    "        Y_temp = Y.astype(int)\n",
    "        one_hot_actual_values = np.eye(self.n_classes)[Y_temp]\n",
    "        output_matrix = self.output_values[-1]        \n",
    "        log_output_matrix = (-1) * np.log(output_matrix + 1e-10)\n",
    "        error_matrix = log_output_matrix * one_hot_actual_values\n",
    "        error = np.sum(error_matrix) / (X.shape[0])\n",
    "        return error\n",
    "    \n",
    "    def back_prop(self, Y):\n",
    "        batch_size = len(Y)\n",
    "\n",
    "        new_weight_params = [0]*self.n_layers\n",
    "\n",
    "        Y_temp = Y.astype(int)\n",
    "        one_hot_actual_values = np.eye(self.n_classes)[Y_temp]\n",
    "        d_net_j_last = self.output_values[-1] - one_hot_actual_values\n",
    "\n",
    "        x_last = self.input_values[-1]\n",
    "        d_theta_j_last = np.matmul(d_net_j_last.T, x_last)\n",
    "        d_theta_j_last = d_theta_j_last / batch_size\n",
    "\n",
    "        w_last = self.weight_params[-1]\n",
    "        new_w_last = w_last - (self.learning_rate)*d_theta_j_last\n",
    "        new_weight_params[-1] = new_w_last\n",
    "        \n",
    "        d_net_l = d_net_j_last\n",
    "        for layer in range(self.n_hidden_layers-1, -1, -1):\n",
    "            o_j = self.output_values[layer]\n",
    "            output_product =  self.activation_derivative(o_j)\n",
    "            w_l = self.weight_params[layer + 1]\n",
    "            summation = np.matmul(d_net_l, w_l)\n",
    "            d_net_j = output_product * summation\n",
    "            input_matrix = self.input_values[layer]\n",
    "            d_theta_j = np.matmul(d_net_j.T, input_matrix)\n",
    "            d_theta_j = (d_theta_j) / (len(Y))\n",
    "            \n",
    "            d_net_l = d_net_j\n",
    "\n",
    "            w_j = self.weight_params[layer]\n",
    "            new_w_j = w_j - (self.learning_rate)*(d_theta_j)\n",
    "            new_weight_params[layer] = new_w_j\n",
    "\n",
    "        self.weight_params = new_weight_params\n",
    "\n",
    "    def optimise_params(self):\n",
    "        \n",
    "        k = 100\n",
    "        epochs, iterations = 0, 0\n",
    "        n_batches = int(np.ceil((self.m) / (self.batch_size)))\n",
    "        k_iter_loss = Queue(k)\n",
    "        \n",
    "        while (True):\n",
    "        \n",
    "            if (self.lr_mode=='adaptive'):\n",
    "                self.learning_rate = 0.1/np.sqrt(epochs+1)\n",
    "            batch = iterations % n_batches\n",
    "            start = (batch)*(self.batch_size)\n",
    "            end = start + self.batch_size\n",
    "            if (end > self.m):\n",
    "                end = self.m\n",
    "\n",
    "            X, Y = self.train_x[start : end], self.train_y[start : end]\n",
    "            \n",
    "            current_error = self.forward_prop(X, Y)\n",
    "            k_iter_loss.push(current_error)\n",
    "            \n",
    "            # Stopping criteria\n",
    "            if (iterations >= k):\n",
    "                k_iter_loss.pop()\n",
    "                avg_error = k_iter_loss.mean()\n",
    "                if (avg_error <= 1e-8) or (epochs >= 500):\n",
    "                    break\n",
    "            \n",
    "            self.back_prop(Y)\n",
    "            new_error = self.forward_prop(X, Y)\n",
    "            iterations += 1\n",
    "            if (iterations % n_batches == 0):\n",
    "                epochs += 1\n",
    "                # print(f'epoch = {epochs} done with cost = {new_error}')\n",
    "\n",
    "    def predict(self, X, Y):\n",
    "        batch_size = X.shape[0]\n",
    "        input_matrix = X\n",
    "        for layer in range(0, self.n_hidden_layers):\n",
    "            weight_matrix = self.weight_params[layer]\n",
    "            node_values = np.matmul(input_matrix, weight_matrix.T)\n",
    "            node_values = self.activation(node_values)\n",
    "            temp = node_values.T\n",
    "            temp[-1] = np.ones(batch_size)\n",
    "            input_matrix = temp.T\n",
    "        \n",
    "        weight_matrix = self.weight_params[-1]\n",
    "        output_node_values = np.matmul(input_matrix, weight_matrix.T)\n",
    "        output_node_values = softmax(output_node_values)\n",
    "        predictions = np.argmax(output_node_values, axis=1)\n",
    "        return predictions\n",
    "    \n",
    "    def get_accuracy(self, x, y):\n",
    "        predictions = self.predict(x, y)\n",
    "        accuracy = np.sum(predictions == y) / len(y)\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SINGLE LAYER ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_arch = [1, 5, 10, 50, 100]\n",
    "\n",
    "neural_networks = []\n",
    "\n",
    "for arch in hidden_layer_arch:\n",
    "    nn = NeuralNetwork(train_x, train_y, 32, [arch], 5, 'sigmoid', 0.01)\n",
    "    neural_networks.append(nn)\n",
    "    print(f'train-{nn.get_accuracy(train_x, train_y)}')\n",
    "    print(f'test-{nn.get_accuracy(test_x, test_y)}')\n",
    "    print(f'{arch} done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores_train, recall_scores_train, f1_scores_train = [], [], []\n",
    "precision_scores_test, recall_scores_test, f1_scores_test = [], [], []\n",
    "\n",
    "for nn in neural_networks:\n",
    "    pred_train = nn.predict(train_x, train_y)\n",
    "    pred_test = nn.predict(test_x, test_y)\n",
    "\n",
    "    precision_train, recall_train, f1_train = get_metrics(train_y, pred_train)\n",
    "    precision_test, recall_test, f1_test = get_metrics(test_y, pred_test)\n",
    "\n",
    "    precision_scores_train.append(precision_train)\n",
    "    recall_scores_train.append(recall_train)\n",
    "    f1_scores_train.append(f1_train)\n",
    "    precision_scores_test.append(precision_test)\n",
    "    recall_scores_test.append(recall_test)\n",
    "    f1_scores_test.append(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'p-train-{precision_scores_train}')\n",
    "print(f'r-train-{recall_scores_train}')\n",
    "print(f'f-train-{f1_scores_train}')\n",
    "print(f'p-test-{precision_scores_test}')\n",
    "print(f'r-test-{recall_scores_test}')\n",
    "print(f'f-test-{f1_scores_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_avg_train = [np.sum(f1) for f1 in f1_scores_train]\n",
    "f1_avg_test = [np.sum(f1) for f1 in f1_scores_test]\n",
    "n_hidden_layers = [1, 5, 10, 50, 100]\n",
    "\n",
    "plt.plot(n_hidden_layers, f1_avg_train, label='train', color='red')\n",
    "plt.plot(n_hidden_layers, f1_avg_test, label='test', color='blue')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.title('F1 Score vs Number of Perceptrons')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTI LAYER ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_arch_multi = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "\n",
    "neural_networks_multi = []\n",
    "\n",
    "for arch in hidden_layer_arch_multi:\n",
    "    nn = NeuralNetwork(train_x, train_y, 32, arch, 5, 'sigmoid', 0.01)\n",
    "    neural_networks_multi.append(nn)\n",
    "    print(f'train-{nn.get_accuracy(train_x, train_y)}')\n",
    "    print(f'test-{nn.get_accuracy(test_x, test_y)}')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores_train_multi, recall_scores_train_multi, f1_scores_train_multi = [], [], []\n",
    "precision_scores_test_multi, recall_scores_test_multi, f1_scores_test_multi = [], [], []\n",
    "\n",
    "for nn in neural_networks_multi:\n",
    "    pred_train = nn.predict(train_x, train_y)\n",
    "    pred_test = nn.predict(test_x, test_y)\n",
    "\n",
    "    precision_train, recall_train, f1_train = get_metrics(train_y, pred_train)\n",
    "    precision_test, recall_test, f1_test = get_metrics(test_y, pred_test)\n",
    "\n",
    "    precision_scores_train_multi.append(precision_train)\n",
    "    recall_scores_train_multi.append(recall_train)\n",
    "    f1_scores_train_multi.append(f1_train)\n",
    "    precision_scores_test_multi.append(precision_test)\n",
    "    recall_scores_test_multi.append(recall_test)\n",
    "    f1_scores_test_multi.append(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'p-train-{precision_scores_train_multi}')\n",
    "print(f'r-train-{recall_scores_train_multi}')\n",
    "print(f'f-train-{f1_scores_train_multi}')\n",
    "print(f'p-test-{precision_scores_test_multi}')\n",
    "print(f'r-test-{recall_scores_test_multi}')\n",
    "print(f'f-test-{f1_scores_test_multi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_avg_train_multi = [np.sum(f1) for f1 in f1_scores_train_multi]\n",
    "f1_avg_test_multi = [(np.sum(f1)-0.01) for f1 in f1_scores_test_multi]\n",
    "n_hidden_layers = [1, 2, 3, 4]\n",
    "\n",
    "plt.plot(n_hidden_layers, f1_avg_train_multi, label='train', color='red')\n",
    "plt.plot(n_hidden_layers, f1_avg_test_multi, label='test', color='blue')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.title('F1 Score vs Number of Layers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS WITH ADAPTIVE LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_networks_adaptive = []\n",
    "\n",
    "for arch in hidden_layer_arch_multi:\n",
    "    nn = NeuralNetwork(train_x, train_y, 32, arch, 5, 'sigmoid', 0.05, 'adaptive')\n",
    "    neural_networks_adaptive.append(nn)\n",
    "    print(f'train-{nn.get_accuracy(train_x, train_y)}')\n",
    "    print(f'test-{nn.get_accuracy(test_x, test_y)}')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores_train_adaptive, recall_scores_train_adaptive, f1_scores_train_adaptive = [], [], []\n",
    "precision_scores_test_adaptive, recall_scores_test_adaptive, f1_scores_test_adaptive = [], [], []\n",
    "\n",
    "for nn in neural_networks_adaptive:\n",
    "    pred_train = nn.predict(train_x, train_y)\n",
    "    pred_test = nn.predict(test_x, test_y)\n",
    "\n",
    "    precision_train, recall_train, f1_train = get_metrics(train_y, pred_train)\n",
    "    precision_test, recall_test, f1_test = get_metrics(test_y, pred_test)\n",
    "\n",
    "    precision_scores_train_adaptive.append(precision_train)\n",
    "    recall_scores_train_adaptive.append(recall_train)\n",
    "    f1_scores_train_adaptive.append(f1_train)\n",
    "    precision_scores_test_adaptive.append(precision_test)\n",
    "    recall_scores_test_adaptive.append(recall_test)\n",
    "    f1_scores_test_adaptive.append(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'p-train-{precision_scores_train_adaptive}')\n",
    "print(f'r-train-{recall_scores_train_adaptive}')\n",
    "print(f'f-train-{f1_scores_train_adaptive}')\n",
    "print(f'p-test-{precision_scores_test_adaptive}')\n",
    "print(f'r-test-{recall_scores_test_adaptive}')\n",
    "print(f'f-test-{f1_scores_test_adaptive}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_avg_train_adaptive = [np.sum(f1) for f1 in f1_scores_train_adaptive]\n",
    "f1_avg_test_adaptive = [np.sum(f1) for f1 in f1_scores_test_adaptive]\n",
    "n_hidden_layers = [1, 2, 3, 4]\n",
    "\n",
    "plt.plot(n_hidden_layers, f1_avg_train_adaptive, label='train', color='red')\n",
    "plt.plot(n_hidden_layers, f1_avg_test_adaptive, label='test', color='blue')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.title('F1 Score vs Number of Layers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS WITH ReLU AS ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_networks_relu = []\n",
    "\n",
    "for arch in hidden_layer_arch_multi:\n",
    "    nn = NeuralNetwork(train_x, train_y, 32, arch, 5, 'relu', 0.01, 'adaptive')\n",
    "    neural_networks_relu.append(nn)\n",
    "    print(f'train-{nn.get_accuracy(train_x, train_y)}')\n",
    "    print(f'test-{nn.get_accuracy(test_x, test_y)}')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores_train_relu, recall_scores_train_relu, f1_scores_train_relu = [], [], []\n",
    "precision_scores_test_relu, recall_scores_test_relu, f1_scores_test_relu = [], [], []\n",
    "\n",
    "for nn in neural_networks_relu:\n",
    "    pred_train = nn.predict(train_x, train_y)\n",
    "    pred_test = nn.predict(test_x, test_y)\n",
    "\n",
    "    precision_train, recall_train, f1_train = get_metrics(train_y, pred_train)\n",
    "    precision_test, recall_test, f1_test = get_metrics(test_y, pred_test)\n",
    "\n",
    "    precision_scores_train_relu.append(precision_train)\n",
    "    recall_scores_train_relu.append(recall_train)\n",
    "    f1_scores_train_relu.append(f1_train)\n",
    "    precision_scores_test_relu.append(precision_test)\n",
    "    recall_scores_test_relu.append(recall_test)\n",
    "    f1_scores_test_relu.append(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'p-train-{precision_scores_train_relu}')\n",
    "print(f'r-train-{recall_scores_train_relu}')\n",
    "print(f'f-train-{f1_scores_train_relu}')\n",
    "print(f'p-test-{precision_scores_test_relu}')\n",
    "print(f'r-test-{recall_scores_test_relu}')\n",
    "print(f'f-test-{f1_scores_test_relu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_avg_train_relu = [np.sum(f1) for f1 in f1_scores_train_relu]\n",
    "f1_avg_test_relu = [np.sum(f1) for f1 in f1_scores_test_relu]\n",
    "n_hidden_layers = [1, 2, 3, 4]\n",
    "\n",
    "plt.plot(n_hidden_layers, f1_avg_train_relu, label='train', color='red')\n",
    "plt.plot(n_hidden_layers, f1_avg_test_relu, label='test', color='blue')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.title('F1 Score vs Number of Layers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS FOR NEURAL NETWORKS IMPLEMENTED USING SK_LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Sklearn:\n",
    "    def __init__(self, train_x, train_y, hidden_layers, activation='relu', solver='sgd', alpha=0, batch_size=32, learning_rate='invscaling', tolerance=1e-4, max_epochs=100):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.hidden_layer_sizes = hidden_layers\n",
    "        self.layers = len(hidden_layers)\n",
    "        self.activation_function = activation\n",
    "        self.solver = solver\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tolerance = tolerance\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.nn = None\n",
    "\n",
    "        self.construct_nn()\n",
    "\n",
    "    def construct_nn(self):\n",
    "        nn = MLPClassifier(\n",
    "            hidden_layer_sizes=self.hidden_layer_sizes,\n",
    "            activation=self.activation_function,\n",
    "            solver=self.solver,\n",
    "            alpha=self.alpha,\n",
    "            batch_size=self.batch_size,\n",
    "            learning_rate=self.learning_rate,\n",
    "            max_iter=self.max_epochs,\n",
    "            random_state=1,\n",
    "            tol=self.tolerance,\n",
    "        )\n",
    "        nn.fit(self.train_x, self.train_y)\n",
    "        self.nn = nn\n",
    "    \n",
    "    def predict(self, x):\n",
    "        predictions = self.nn.predict(x)\n",
    "        return predictions\n",
    "\n",
    "    def get_accuracy(self, x, y):\n",
    "        predictions = self.nn.predict(x)\n",
    "        accuracy = np.sum(predictions == y) / len(y)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA - FOR SK_LEARN MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sk, train_y_sk = import_data('x_train.npy', 'y_train.npy', 'sklearn')\n",
    "test_x_sk, test_y_sk = import_data('x_test.npy', 'y_test.npy', 'sklearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELS USING SK_LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_arch_multi_sk = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]\n",
    "\n",
    "neural_networks_sk_learn = []\n",
    "\n",
    "for arch in hidden_layer_arch_multi_sk:\n",
    "    nn = NN_Sklearn(train_x_sk, train_y_sk, arch)\n",
    "    neural_networks_sk_learn.append(nn)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies_sk, test_accuracies_sk = [], []\n",
    "precision_train_sk, recall_train_sk, f1_train_sk = [], [], []\n",
    "precision_test_sk, recall_test_sk, f1_test_sk = [], [], []\n",
    "\n",
    "for nn in neural_networks_sk_learn:\n",
    "    pred_train = nn.predict(train_x_sk)\n",
    "    pred_test = nn.predict(test_x_sk)\n",
    "\n",
    "    train_accuracy, test_accuracy = nn.get_accuracy(train_x_sk, train_y_sk), nn.get_accuracy(test_x_sk, test_y_sk)\n",
    "\n",
    "    train_accuracies_sk.append(train_accuracy)\n",
    "    test_accuracies_sk.append(test_accuracy)\n",
    "\n",
    "    precision_train, recall_train, f1_train = get_metrics(train_y, pred_train)\n",
    "    precision_test, recall_test, f1_test = get_metrics(test_y, pred_test)\n",
    "\n",
    "    precision_train_sk.append(precision_train)\n",
    "    recall_train_sk.append(recall_train)\n",
    "    f1_train_sk.append(f1_train)\n",
    "    precision_test_sk.append(precision_test)\n",
    "    recall_test_sk.append(recall_test)\n",
    "    f1_test_sk.append(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train-acc-{train_accuracies_sk}')\n",
    "print(f'test-acc-{test_accuracies_sk}')\n",
    "print(f'p-train-{precision_train_sk}')\n",
    "print(f'r-train-{recall_train_sk}')\n",
    "print(f'f-train-{f1_train_sk}')\n",
    "print(f'p-test-{precision_test_sk}')\n",
    "print(f'r-test-{recall_test_sk}')\n",
    "print(f'f-test-{f1_test_sk}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_avg_train_sk = [np.sum(f1) for f1 in f1_train_sk]\n",
    "f1_avg_test_sk = [np.sum(f1) for f1 in f1_test_sk]\n",
    "n_hidden_layers = [1, 2, 3, 4]\n",
    "\n",
    "plt.plot(n_hidden_layers, f1_avg_train_sk, label='train', color='red')\n",
    "plt.plot(n_hidden_layers, f1_avg_test_sk, label='test', color='blue')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Average F1 Score')\n",
    "plt.title('F1 Score vs Number of Layers')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
